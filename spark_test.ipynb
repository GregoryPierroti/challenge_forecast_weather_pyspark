{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "580dd39c-f066-4c32-af47-648eb71f5918",
   "metadata": {
    "id": "580dd39c-f066-4c32-af47-648eb71f5918",
    "tags": []
   },
   "source": [
    "# Desafio: Consumo de Dados para Previsão do Tempo das Cidades do Vale do Paraíba.\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Avaliar conhecimentos nas linguagens Python e SQL e na engine de processamento Apache Spark.\n",
    "\n",
    "## Descrição\n",
    "\n",
    "Neste desafio, você desenvolverá um notebook que será responsável por extrair dados de previsão do tempo das cidades do Vale do Paraíba. Para consultar todas as cidades dessa região, utilizaremos a API do IBGE. No caso, basta realizar uma requisição HTTP com o método GET, utilizando a URL abaixo:\n",
    "\n",
    "```\n",
    "https://servicodados.ibge.gov.br/api/v1/localidades/mesorregioes/3513/municipios\n",
    "```\n",
    "\n",
    "Com esses dados, gerar um data frame e a partir dele uma temp view. Ex: \"cities\"\n",
    "\n",
    "Utilizando os nomes das cidades, deverão ser consultados os dados de previsão de tempo para cada cidade. Para realizar essa consulta, poderá ser utilizada qualquer uma das APIs informadas no link abaixo.\n",
    "\n",
    "[Public APIs - Wather](https://github.com/public-apis/public-apis#weather)\n",
    "\n",
    "Obs.: Para algumas, pode ser necessário cadastrar-se para acessar sua API Key. Mas nenhuma delas deve precisar cadastrar cartão de crédito ou adicionar qualquer valor monetário para utilizar. Caso alguma solicite, basta optar por outra.\n",
    "\n",
    "Com os dados consultados, gerar um data frame e partir dele outra temp view. Ex: \"forecasts\"\n",
    "\n",
    "Com as temp views geradas, utilizar Spark SQL para criar queries e gerar data frames das seguintes tabelas:\n",
    "\n",
    "- Tabela 1: dados de previsão do tempo para os próximos cinco dias, para cada data e cidade consultadas. As colunas dessa tabela serão:\n",
    "    - Cidade\n",
    "    - CodigoDaCidade\n",
    "    - Data\n",
    "    - Regiao\n",
    "    - Pais\n",
    "    - Latitude\n",
    "    - Longigute\n",
    "    - TemperaturaMaxima\n",
    "    - TemperaturaMinima\n",
    "    - TemperaturaMedia\n",
    "    - VaiChover\n",
    "    - ChanceDeChuva\n",
    "    - CondicaoDoTempo\n",
    "    - NascerDoSol\n",
    "    - PorDoSol\n",
    "    - VelocidadeMaximaDoVento\n",
    "    \n",
    "    Obs.: Os valores da coluna \"VaiChover\" deverá ser \"Sim\" ou \"Não\". E a coluna \"CodigoDaCidade\" é o ID retornado junto com os nomes da cidades na API do IBGE.\n",
    "    Obs.: Dependendo da API utilizada, algumas colunas podem não existir e ficarão em branco. Você deve optar por uma API que traga o maior número de informações possível.\n",
    "\n",
    "- Tabela 2: quantidade de dias com chuva e sem chuva para os dias consultados, para cada data consultada. Colunas:\n",
    "    - Cidade\n",
    "    - QtdDiasVaiChover\n",
    "    - QtdDiasNaoVaiChover\n",
    "    - TotalDiasMapeados\n",
    "\n",
    "Essas tabelas deverão ser exportadas em formado CSV e entregue no final do desafio.\n",
    "\n",
    "## To Do\n",
    "\n",
    "[ ] - Consultar municípios do Vale do Paraíba, gerar um data frame e criar uma temp view com esses dados.\n",
    "[ ] - Consultar dados do tempo para cada município, gerar um data frame e criar uma outra temp view.\n",
    "[ ] - Utilizar Spark SQL para gerar os data frames das Tabelas 1 e 2.\n",
    "[ ] - Exportar os data frames para CSV.\n",
    "\n",
    "## Atenção\n",
    "\n",
    "- Existe um limite de requisições de 10000 requests por conta cadastrada na m3o.\n",
    "- Essa API pode retornar cidades de outras regiões que possuem nome semelhante a alguma cidade do Vale do Paraiba. Pode mantê-las ou filtrar para gerar as tabelas apenas com dados de Regiao = Sao Paulo. Fica a seu critério.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "NV0BOf-a0vNY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NV0BOf-a0vNY",
    "outputId": "e1b07a35-a12f-4b23-f868-afaf2c340ed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 281.3 MB 50 kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 51.3 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=395ed1a54afac0bff43e0970cbe7917b82ceea8cb4b6ed351a888e0167750364\n",
      "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting jupyterlab\n",
      "  Downloading jupyterlab-3.4.6-py3-none-any.whl (8.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.8 MB 7.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from jupyterlab) (4.11.1)\n",
      "Collecting jupyter-server~=1.16\n",
      "  Downloading jupyter_server-1.18.1-py3-none-any.whl (344 kB)\n",
      "\u001b[K     |████████████████████████████████| 344 kB 45.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyterlab) (7.9.0)\n",
      "Collecting nbclassic\n",
      "  Downloading nbclassic-0.4.3-py3-none-any.whl (9.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.7 MB 49.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: notebook<7 in /usr/local/lib/python3.7/dist-packages (from jupyterlab) (5.3.1)\n",
      "Collecting tornado>=6.1.0\n",
      "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
      "\u001b[K     |████████████████████████████████| 423 kB 57.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from jupyterlab) (21.3)\n",
      "Collecting jupyterlab-server~=2.10\n",
      "  Downloading jupyterlab_server-2.15.1-py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: jinja2>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.1->jupyterlab) (2.0.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab) (23.2.1)\n",
      "Collecting anyio<4,>=3.1.0\n",
      "  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 9.7 MB/s \n",
      "\u001b[?25hCollecting prometheus-client\n",
      "  Downloading prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 7.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab) (6.1.12)\n",
      "Collecting argon2-cffi\n",
      "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting nbconvert>=6.4.4\n",
      "  Downloading nbconvert-7.0.0-py3-none-any.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 66.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab) (0.13.3)\n",
      "Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab) (5.4.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab) (5.1.1)\n",
      "Collecting websocket-client\n",
      "  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 3.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.16->jupyterlab) (2.10)\n",
      "Collecting sniffio>=1.1\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.16->jupyterlab) (4.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->jupyter-server~=1.16->jupyterlab) (2.8.2)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab) (4.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab) (2.23.0)\n",
      "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab) (2.10.3)\n",
      "Collecting json5\n",
      "  Downloading json5-0.9.10-py2.py3-none-any.whl (19 kB)\n",
      "Collecting jinja2>=2.1\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 60.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab) (4.3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->jupyterlab-server~=2.10->jupyterlab) (3.8.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab) (5.9.0)\n",
      "Collecting mistune<3,>=2.0.3\n",
      "  Downloading mistune-2.0.4-py2.py3-none-any.whl (24 kB)\n",
      "Collecting nbclient>=0.5.0\n",
      "  Downloading nbclient-0.6.8-py3-none-any.whl (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 200 kB/s \n",
      "\u001b[?25hRequirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (4.9.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (4.6.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (5.0.1)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (2.6.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (1.5.0)\n",
      "Collecting tinycss2\n",
      "  Downloading tinycss2-1.1.1-py3-none-any.whl (21 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting traitlets>=5.1\n",
      "  Downloading traitlets-5.3.0-py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 72.1 MB/s \n",
      "\u001b[?25hCollecting nest-asyncio\n",
      "  Downloading nest_asyncio-1.5.5-py3-none-any.whl (5.2 kB)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=5.2.0->jupyter-server~=1.16->jupyterlab) (2.16.1)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook<7->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook<7->jupyterlab) (5.3.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->jupyter-server~=1.16->jupyterlab) (1.15.0)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.3->jupyter-server~=1.16->jupyterlab) (0.7.0)\n",
      "Collecting argon2-cffi-bindings\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 5.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.16->jupyterlab) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.16->jupyterlab) (2.21)\n",
      "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->jupyterlab-server~=2.10->jupyterlab) (2022.2.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (0.5.1)\n",
      "Collecting jedi>=0.10\n",
      "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 51.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab) (57.4.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab) (4.4.2)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab) (2.0.10)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->jupyterlab) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->jupyterlab) (0.2.5)\n",
      "Collecting notebook-shim>=0.1.0\n",
      "  Downloading notebook_shim-0.1.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->jupyterlab) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.10->jupyterlab) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.10->jupyterlab) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.10->jupyterlab) (1.24.3)\n",
      "Installing collected packages: traitlets, tornado, nest-asyncio, tinycss2, sniffio, nbclient, mistune, jupyterlab-pygments, jinja2, argon2-cffi-bindings, websocket-client, prometheus-client, nbconvert, jedi, argon2-cffi, anyio, jupyter-server, notebook-shim, json5, nbclassic, jupyterlab-server, jupyterlab\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.1.1\n",
      "    Uninstalling traitlets-5.1.1:\n",
      "      Successfully uninstalled traitlets-5.1.1\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 5.1.1\n",
      "    Uninstalling tornado-5.1.1:\n",
      "      Successfully uninstalled tornado-5.1.1\n",
      "  Attempting uninstall: mistune\n",
      "    Found existing installation: mistune 0.8.4\n",
      "    Uninstalling mistune-0.8.4:\n",
      "      Successfully uninstalled mistune-0.8.4\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 2.11.3\n",
      "    Uninstalling Jinja2-2.11.3:\n",
      "      Successfully uninstalled Jinja2-2.11.3\n",
      "  Attempting uninstall: nbconvert\n",
      "    Found existing installation: nbconvert 5.6.1\n",
      "    Uninstalling nbconvert-5.6.1:\n",
      "      Successfully uninstalled nbconvert-5.6.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.2 which is incompatible.\n",
      "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\u001b[0m\n",
      "Successfully installed anyio-3.6.1 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 jedi-0.18.1 jinja2-3.1.2 json5-0.9.10 jupyter-server-1.18.1 jupyterlab-3.4.6 jupyterlab-pygments-0.2.2 jupyterlab-server-2.15.1 mistune-2.0.4 nbclassic-0.4.3 nbclient-0.6.8 nbconvert-7.0.0 nest-asyncio-1.5.5 notebook-shim-0.1.0 prometheus-client-0.14.1 sniffio-1.3.0 tinycss2-1.1.1 tornado-6.2 traitlets-5.3.0 websocket-client-1.4.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "tornado"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
      "\u001b[K     |████████████████████████████████| 235 kB 7.4 MB/s \n",
      "\u001b[?25hInstalling collected packages: unidecode\n",
      "Successfully installed unidecode-1.3.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pyspark\n",
    "!pip install pyspark\n",
    "\n",
    "# findspark\n",
    "!pip install findspark\n",
    "\n",
    "# jupyterlab\n",
    "!pip install jupyterlab\n",
    "\n",
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6313d6bb",
   "metadata": {
    "id": "6313d6bb"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import requests, os, shutil\n",
    "import json\n",
    "import unidecode\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local[1]\") \\\n",
    "      .appName(\"SparkByExamples.com\") \\\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jzhrieaMDTY5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jzhrieaMDTY5",
    "outputId": "536dad8b-ce92-417e-ddf4-48dede947f82"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H9t7qS63oUkP",
   "metadata": {
    "id": "H9t7qS63oUkP"
   },
   "source": [
    "# Criação dos caminhos que serão utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "Bin9s5B7oTUP",
   "metadata": {
    "id": "Bin9s5B7oTUP"
   },
   "outputs": [],
   "source": [
    "path_arquivos = '/content/drive/MyDrive/arquivos/'\n",
    "path_previsao = '/content/drive/MyDrive/arquivos/previsao/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CSWeaf5eGVUF",
   "metadata": {
    "id": "CSWeaf5eGVUF"
   },
   "source": [
    "# Buscando Cidades do vale do Paraíba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "SwJD8WUFhmjx",
   "metadata": {
    "id": "SwJD8WUFhmjx"
   },
   "outputs": [],
   "source": [
    "#acessando a API e transformando a response json em uma string para criar arquivo no drive\n",
    "municipios = requests.get('https://servicodados.ibge.gov.br/api/v1/localidades/mesorregioes/3513/municipios')\n",
    "municipios = municipios.json()\n",
    "str_municipios = json.dumps(municipios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6pa1Sdh-s4",
   "metadata": {
    "id": "be6pa1Sdh-s4"
   },
   "source": [
    "# Criando arquivo contendo as informações da API de municipios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "AYrv5FuBh-_Q",
   "metadata": {
    "id": "AYrv5FuBh-_Q"
   },
   "outputs": [],
   "source": [
    "#abrindo o arquivo json\n",
    "file = open(path_arquivos+'arq.json', \"w\")\n",
    " \n",
    "#Escreve no arquivo\n",
    "file.write(str_municipios)\n",
    " \n",
    "#Fecha o arquivo com os dados da api salvos\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1DvADwIYiUNK",
   "metadata": {
    "id": "1DvADwIYiUNK"
   },
   "source": [
    "# Criação do DF cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3p-2HMDhiU-o",
   "metadata": {
    "id": "3p-2HMDhiU-o"
   },
   "outputs": [],
   "source": [
    "\n",
    "df_cidades = spark.read.json(path_arquivos+'arq.json')\n",
    "\n",
    "#Ajuste do dataframe\n",
    "cities = df_cidades.select(\n",
    "      col(\"id\"),\n",
    "      col(\"nome\"),\n",
    "      col(\"microrregiao.id\").alias(\"id_microrregiao\"),\n",
    "      col(\"microrregiao.nome\").alias(\"nome_microrregiao\"),\n",
    "      col(\"microrregiao.mesorregiao.UF.id\").alias(\"id_uf_microrregiao\"),\n",
    "      col(\"microrregiao.mesorregiao.UF.nome\").alias(\"nome_uf_microrregiao\"),\n",
    "      col(\"microrregiao.mesorregiao.UF.sigla\").alias(\"sigla_uf_micorregiao\"),\n",
    "      col(\"microrregiao.mesorregiao.UF.regiao.id\").alias(\"id_regiao_microrregiao\"),\n",
    "      col(\"microrregiao.mesorregiao.UF.regiao.nome\").alias(\"nome_regiao_microrregiao\"),\n",
    "      col(\"microrregiao.mesorregiao.UF.regiao.sigla\").alias(\"sigla_regiao_microrregiao\"),\n",
    "      col(\"regiao-imediata.id\").alias(\"id_regiao_imediata\"),\n",
    "      col(\"regiao-imediata.nome\").alias(\"nome_regiao_imediata\"),\n",
    "      col(\"regiao-imediata.regiao-intermediaria.id\").alias(\"id_regiao_intermediaria\"),\n",
    "      col(\"regiao-imediata.regiao-intermediaria.nome\").alias(\"nome_regiao_intermediaria\"),\n",
    "      col(\"regiao-imediata.regiao-intermediaria.UF.id\").alias(\"id_uf_regiao_imediata\"),\n",
    "      col(\"regiao-imediata.regiao-intermediaria.UF.nome\").alias(\"nome_uf_regiao_imediata\"),\n",
    "      col(\"regiao-imediata.regiao-intermediaria.UF.sigla\").alias(\"sigla_uf_regiao_imediata\"),\n",
    "      col(\"regiao-imediata.regiao-intermediaria.UF.regiao.id\").alias(\"id_regiao_regiao_imediata\"),\n",
    "      col(\"regiao-imediata.regiao-intermediaria.UF.regiao.nome\").alias(\"nome_regiao_regiao_imediata\"),\n",
    "      col(\"regiao-imediata.regiao-intermediaria.UF.regiao.sigla\").alias(\"sigla_regiao_regiao_imediata\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_d0eps31irXj",
   "metadata": {
    "id": "_d0eps31irXj"
   },
   "source": [
    "# CRIAÇÃO DA VIEW CIDADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdc739f4-2ebf-4ff2-91ff-89689510e618",
   "metadata": {
    "id": "cdc739f4-2ebf-4ff2-91ff-89689510e618",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cities.createOrReplaceTempView(\"VW_CIDADES\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uNDtSEzwGrvW",
   "metadata": {
    "id": "uNDtSEzwGrvW"
   },
   "source": [
    "#  Buscar previsão do tempo para as cidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AaUBUme1jxe5",
   "metadata": {
    "id": "AaUBUme1jxe5"
   },
   "source": [
    "### Lista criada para coletar os nomes das cidades e usar na consulta da API (Consulta o primeiro DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "iCDo3BTKjvUw",
   "metadata": {
    "id": "iCDo3BTKjvUw"
   },
   "outputs": [],
   "source": [
    "lista_cidades = cities.select('nome').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3wuKh1aVj_IF",
   "metadata": {
    "id": "3wuKh1aVj_IF"
   },
   "source": [
    "### Abaixo nós temos a Key da Segunda API de previsão do tempo, ela é limitada por consulta, então na variavel, vai ser a key usada, caso ela expire( Questão na qual poderemos acompanhar em células abaixo, substituir por outra key encontrada no comentario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "NbxTR5l0keKP",
   "metadata": {
    "id": "NbxTR5l0keKP"
   },
   "outputs": [],
   "source": [
    "key = 'ded6401a'\n",
    "#  '82f74bad', 'ccadb0c5', '7a06c130'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2LmBPfiDkgum",
   "metadata": {
    "id": "2LmBPfiDkgum"
   },
   "source": [
    "# Consulta na API com as previsões\n",
    "#### Dentro do loop também esta criando arquivos contendo as informações da API de cada municipio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "qOF_UcQHk4TU",
   "metadata": {
    "id": "qOF_UcQHk4TU"
   },
   "outputs": [],
   "source": [
    "for i in lista_cidades:\n",
    "  previsao  =requests.get('https://api.hgbrasil.com/weather?key='+key+'&city_name=' + i +',SP')\n",
    "  previsao = previsao.json()\n",
    "  str_previsao = json.dumps(previsao)\n",
    "  #criando o arquivo json\n",
    "  file = open(path_previsao+ i +'.json', \"w\")\n",
    " \n",
    "  #Escreve no arquivo\n",
    "  file.write(str_previsao)\n",
    " \n",
    "  #Fecha o arquivo com os dados da api salvos\n",
    "  file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y4qjRehAk74D",
   "metadata": {
    "id": "y4qjRehAk74D"
   },
   "source": [
    "# É criado um dataframe com a estrutura dos arquivos json\n",
    "### Como há arrays  no json, é necessario realizar um explode, em seguida do recolhimento das colunas do array, a coluna array é deletada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "qOYduwcNlEkD",
   "metadata": {
    "id": "qOYduwcNlEkD"
   },
   "outputs": [],
   "source": [
    "\n",
    "df_previsao_cidades = spark.read.json(path_previsao+'*.json')\n",
    "\n",
    "\n",
    "prev = df_previsao_cidades.select(\n",
    "    col(\"results.cid\"), \n",
    "    col(\"results.city\"), \n",
    "    col(\"results.city_name\"), \n",
    "    col(\"results.condition_code\"),\n",
    "    col(\"results.condition_slug\"),\n",
    "    col(\"results.currently\"),\n",
    "    col(\"results.date\"),\n",
    "    col(\"results.description\"),\n",
    "    explode(col(\"results.forecast\")).alias(\"element\"),\n",
    "    col(\"element.condition\"), \n",
    "    col(\"element.date\").alias('date_forecast'), \n",
    "    col(\"element.description\").alias(\"description_detail\"), \n",
    "    col(\"element.max\"),\n",
    "    col(\"element.min\"), \n",
    "    col(\"element.weekday\"),\n",
    "    col(\"results.humidity\"),\n",
    "    col(\"results.img_id\"),\n",
    "    col(\"results.sunrise\"),\n",
    "    col(\"results.sunset\"),\n",
    "    col(\"results.temp\"),\n",
    "    col(\"results.time\"),\n",
    "    col(\"results.wind_speedy\")\n",
    ")\n",
    "prev = prev.drop(\"element\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m16zbcATlkVv",
   "metadata": {
    "id": "m16zbcATlkVv"
   },
   "source": [
    "# Criação da VIEW FORECAST(previsões)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4a40a6f-d5f1-4524-9d0b-d1e6e24dfbfa",
   "metadata": {
    "id": "c4a40a6f-d5f1-4524-9d0b-d1e6e24dfbfa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prev.createOrReplaceTempView(\"VW_FORECAST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rbgmZQpJJAbn",
   "metadata": {
    "id": "rbgmZQpJJAbn"
   },
   "source": [
    "##### Se aparecer alguma tela de erro, é porque a key expirou, caso seja necessário, é possível trocar na variável algumas celulas acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "zSFJDgsbIT0R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSFJDgsbIT0R",
    "outputId": "98d7583b-5da5-4ba5-8e4d-3c1acffe58d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+----------+--------------------+---------+\n",
      "|       by|execution_time|from_cache|             results|valid_key|\n",
      "+---------+--------------+----------+--------------------+---------+\n",
      "|     null|          0.27|     false|{, São José do Ba...|     true|\n",
      "|city_name|          1.57|     false|{, Tremembé, SP, ...|     true|\n",
      "|city_name|           0.5|     false|{, Santo Antônio ...|     true|\n",
      "|    woeid|          0.29|     false|{, Campos do Jord...|     true|\n",
      "|city_name|          0.16|     false|{, Silveiras, SP,...|     true|\n",
      "|city_name|          0.58|     false|{, São Bento do S...|     true|\n",
      "|city_name|          0.55|     false|{, Lagoinha, SP, ...|     true|\n",
      "|city_name|          0.81|     false|{, Lavrinhas, SP,...|     true|\n",
      "|city_name|          0.52|     false|{, Paraibuna, SP,...|     true|\n",
      "|city_name|           0.0|      true|{, São José dos C...|     true|\n",
      "|city_name|          1.02|     false|{, Cachoeira Paul...|     true|\n",
      "|city_name|          0.33|     false|{, Redenção da Se...|     true|\n",
      "|city_name|          0.38|     false|{, Guaratinguetá,...|     true|\n",
      "|city_name|           0.0|      true|{, Taubaté, SP, T...|     true|\n",
      "|    woeid|          0.55|     false|{, Piquete, SP, P...|    false|\n",
      "|city_name|          0.28|     false|{, São Sebastião,...|     true|\n",
      "|city_name|           0.5|     false|{, Cunha, SP, Cun...|     true|\n",
      "|city_name|           0.6|     false|{, Roseira, SP, R...|     true|\n",
      "|city_name|          0.61|     false|{, Caçapava, SP, ...|     true|\n",
      "|city_name|          0.68|     false|{, Natividade da ...|     true|\n",
      "|city_name|           0.8|     false|{, Aparecida, SP,...|     true|\n",
      "|city_name|          0.07|     false|{, Queluz, SP, Qu...|     true|\n",
      "|    woeid|          0.84|     false|{, Igaratá, SP, I...|    false|\n",
      "|city_name|          0.45|     false|{, Arapeí, SP, Ar...|     true|\n",
      "|city_name|           0.0|      true|{, Cruzeiro, SP, ...|     true|\n",
      "|city_name|          1.08|     false|{, Canas, SP, Can...|     true|\n",
      "|city_name|          0.32|     false|{, Potim, SP, Pot...|     true|\n",
      "|city_name|           0.0|      true|{, São Paulo, SP,...|     true|\n",
      "|city_name|           0.0|      true|{, Jacareí, SP, J...|     true|\n",
      "|city_name|          0.33|     false|{, Caraguatatuba,...|     true|\n",
      "|city_name|          0.56|     false|{, Santa Branca, ...|     true|\n",
      "|city_name|          0.16|     false|{, Bananal, SP, B...|     true|\n",
      "|city_name|           0.0|      true|{, Pindamonhangab...|     true|\n",
      "|city_name|          0.37|     false|{, Areias, SP, Ar...|     true|\n",
      "|city_name|           0.0|      true|{, Lorena, SP, Lo...|     true|\n",
      "|city_name|           0.0|      true|{, Monteiro Lobat...|     true|\n",
      "|city_name|          0.04|     false|{, Ilhabela, SP, ...|     true|\n",
      "|  default|           1.6|     false|{, Jambeiro, SP, ...|    false|\n",
      "|city_name|          0.08|     false|{, Ubatuba, SP, U...|     true|\n",
      "+---------+--------------+----------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_previsao_cidades.show(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m18-4E-hI2yG",
   "metadata": {
    "id": "m18-4E-hI2yG"
   },
   "source": [
    "# VIEW CIDADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "yzVmqSM5TMEF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yzVmqSM5TMEF",
    "outputId": "27521527-749e-48d9-eac7-759cd70ad3e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------------+-------------------+------------------+--------------------+--------------------+----------------------+------------------------+-------------------------+------------------+--------------------+-----------------------+-------------------------+---------------------+-----------------------+------------------------+-------------------------+---------------------------+----------------------------+\n",
      "|     id|     nome|id_microrregiao|  nome_microrregiao|id_uf_microrregiao|nome_uf_microrregiao|sigla_uf_micorregiao|id_regiao_microrregiao|nome_regiao_microrregiao|sigla_regiao_microrregiao|id_regiao_imediata|nome_regiao_imediata|id_regiao_intermediaria|nome_regiao_intermediaria|id_uf_regiao_imediata|nome_uf_regiao_imediata|sigla_uf_regiao_imediata|id_regiao_regiao_imediata|nome_regiao_regiao_imediata|sigla_regiao_regiao_imediata|\n",
      "+-------+---------+---------------+-------------------+------------------+--------------------+--------------------+----------------------+------------------------+-------------------------+------------------+--------------------+-----------------------+-------------------------+---------------------+-----------------------+------------------------+-------------------------+---------------------------+----------------------------+\n",
      "|3502507|Aparecida|          35051|      Guaratinguetá|                35|           São Paulo|                  SP|                     3|                 Sudeste|                       SE|            350052|       Guaratinguetá|                   3511|      São José dos Campos|                   35|              São Paulo|                      SP|                        3|                    Sudeste|                          SE|\n",
      "|3503158|   Arapeí|          35052|            Bananal|                35|           São Paulo|                  SP|                     3|                 Sudeste|                       SE|            350053|            Cruzeiro|                   3511|      São José dos Campos|                   35|              São Paulo|                      SP|                        3|                    Sudeste|                          SE|\n",
      "|3503505|   Areias|          35052|            Bananal|                35|           São Paulo|                  SP|                     3|                 Sudeste|                       SE|            350053|            Cruzeiro|                   3511|      São José dos Campos|                   35|              São Paulo|                      SP|                        3|                    Sudeste|                          SE|\n",
      "|3504909|  Bananal|          35052|            Bananal|                35|           São Paulo|                  SP|                     3|                 Sudeste|                       SE|            350053|            Cruzeiro|                   3511|      São José dos Campos|                   35|              São Paulo|                      SP|                        3|                    Sudeste|                          SE|\n",
      "|3508504| Caçapava|          35050|São José dos Campos|                35|           São Paulo|                  SP|                     3|                 Sudeste|                       SE|            350049| São José dos Campos|                   3511|      São José dos Campos|                   35|              São Paulo|                      SP|                        3|                    Sudeste|                          SE|\n",
      "+-------+---------+---------------+-------------------+------------------+--------------------+--------------------+----------------------+------------------------+-------------------------+------------------+--------------------+-----------------------+-------------------------+---------------------+-----------------------+------------------------+-------------------------+---------------------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM VW_CIDADES\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7NPhngxDI6S2",
   "metadata": {
    "id": "7NPhngxDI6S2"
   },
   "source": [
    "# VIEW PREVISÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "oHpdKf1TQeZW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHpdKf1TQeZW",
    "outputId": "70f6dd86-2ba1-48a9-8bcc-8bccc5538d62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------+--------------+---------+----------+--------------------+-----------+-------------+------------------+---+---+-------+--------+------+--------+--------+----+-----+-----------+\n",
      "|cid|                city|           city_name|condition_code|condition_slug|currently|      date|         description|  condition|date_forecast|description_detail|max|min|weekday|humidity|img_id| sunrise|  sunset|temp| time|wind_speedy|\n",
      "+---+--------------------+--------------------+--------------+--------------+---------+----------+--------------------+-----------+-------------+------------------+---+---+-------+--------+------+--------+--------+----+-----+-----------+\n",
      "|   |São José do Barre...|São José do Barreiro|            29|         cloud|    noite|09/09/2022|Parcialmente nublado|  clear_day|        09/09|       Tempo limpo| 35| 18|    Sex|      34|   29n|06:00 am|05:50 pm|  27|17:54|  0.92 km/h|\n",
      "|   |São José do Barre...|São José do Barreiro|            29|         cloud|    noite|09/09/2022|Parcialmente nublado|  clear_day|        10/09|       Tempo limpo| 37| 18|    Sáb|      34|   29n|06:00 am|05:50 pm|  27|17:54|  0.92 km/h|\n",
      "|   |São José do Barre...|São José do Barreiro|            29|         cloud|    noite|09/09/2022|Parcialmente nublado|cloudly_day|        11/09|     Tempo nublado| 25| 16|    Dom|      34|   29n|06:00 am|05:50 pm|  27|17:54|  0.92 km/h|\n",
      "|   |São José do Barre...|São José do Barreiro|            29|         cloud|    noite|09/09/2022|Parcialmente nublado|       rain|        12/09|   Chuvas esparsas| 31| 16|    Seg|      34|   29n|06:00 am|05:50 pm|  27|17:54|  0.92 km/h|\n",
      "|   |São José do Barre...|São José do Barreiro|            29|         cloud|    noite|09/09/2022|Parcialmente nublado|cloudly_day|        13/09|     Tempo nublado| 35| 16|    Ter|      34|   29n|06:00 am|05:50 pm|  27|17:54|  0.92 km/h|\n",
      "+---+--------------------+--------------------+--------------+--------------+---------+----------+--------------------+-----------+-------------+------------------+---+---+-------+--------+------+--------+--------+----+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM VW_FORECAST\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d_CL8hqCJLNQ",
   "metadata": {
    "id": "d_CL8hqCJLNQ"
   },
   "source": [
    "# DF Tabela 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbc2a925-c707-46f0-a2e2-e0e0164a7312",
   "metadata": {
    "id": "bbc2a925-c707-46f0-a2e2-e0e0164a7312"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Considerei Tempo nublado e chuvas esparsas como dia de chuva\n",
    "tabela1 = spark.sql(\"\"\"SELECT VW_CIDADES.id, VW_CIDADES.nome as cidade,\n",
    "    CONCAT(VW_FORECAST.date_forecast,'/2022') as data, \n",
    "    VW_CIDADES.nome_regiao_microrregiao as regiao,\n",
    "    VW_FORECAST.max as temp_max,\n",
    "    VW_FORECAST.min as temp_min,\n",
    "    (VW_FORECAST.max + VW_FORECAST.min)/2 as temp_media, \n",
    "    case when (VW_FORECAST.description_detail in ('Chuvas esparsas','Tempo nublado'))\n",
    "        then 'Sim' else 'Nao'end as vai_vhover,\n",
    "    VW_FORECAST.description as condicao_do_tempo,\n",
    "    VW_FORECAST.description_detail as chance_de_chuva,\n",
    "    VW_FORECAST.sunrise as nascer_do_sol, \n",
    "    VW_FORECAST.sunset as por_do_sol, \n",
    "    VW_FORECAST.wind_speedy as velocidade_maxima_do_vento \n",
    "    FROM VW_CIDADES \n",
    "      LEFT JOIN VW_FORECAST \n",
    "        ON VW_CIDADES.nome = VW_FORECAST.city_name \n",
    "    WHERE VW_FORECAST.date_forecast in ('09/09', '10/09', '11/09', '12/09','13/09') \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4KzIhoKLJX4M",
   "metadata": {
    "id": "4KzIhoKLJX4M"
   },
   "source": [
    "# DF Tabela 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bab3315-f50b-4269-8823-ccfda0fefbfe",
   "metadata": {
    "id": "3bab3315-f50b-4269-8823-ccfda0fefbfe"
   },
   "outputs": [],
   "source": [
    "tabela2 = spark.sql(\"\"\"SELECT VW_FORECAST.city_name as cidade,\n",
    "    count(case when (VW_FORECAST.description_detail in ('Chuvas esparsas','Tempo nublado')) \n",
    "      then 1 \n",
    "    end) qtd_dias_vai_chover, \n",
    "    count(case when (VW_FORECAST.description_detail not in ('Chuvas esparsas','Tempo nublado')) \n",
    "      then 1 \n",
    "    end) qtd_dias_sem_chover, \n",
    "    count(VW_FORECAST.date_forecast) as total_dias_mapeados \n",
    "    FROM VW_FORECAST \n",
    "    WHERE VW_FORECAST.date_forecast in ('09/09', '10/09', '11/09', '12/09','13/09')\n",
    "      GROUP BY VW_FORECAST.city_name\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KvFbJUICJz-q",
   "metadata": {
    "id": "KvFbJUICJz-q"
   },
   "source": [
    "# Exportar CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1ff378b-4c24-47dc-aba1-742211cd385d",
   "metadata": {
    "id": "c1ff378b-4c24-47dc-aba1-742211cd385d"
   },
   "outputs": [],
   "source": [
    "tabela1.repartition(1).write.mode(\"overwrite\").option(\"header\", \"true\").option(\"delimiter\", \",\").option(\"encoding\", \"ISO-8859-1\").csv(path_arquivos+\"tabela1.csv\")\n",
    "tabela2.repartition(1).write.mode(\"overwrite\").option(\"header\", \"true\").option(\"delimiter\", \",\").option(\"encoding\", \"ISO-8859-1\").csv(path_arquivos+\"tabela2.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
